{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching files in directory: C:\\Users\\ericb\\Desktop\\Research\\Primary@gmail.com\\Cleaned_Mail\\2023_test\\08\\\n",
      "Processing file: _376f0vXRrWR5R6W9rf4NA@geopod-ismtpd-canary-0.txt\n",
      "Processing file: _5hS-rh6QhW8lvdt7USwww@geopod-ismtpd-35.txt\n",
      "Processing file: _AmJSCjkTaeQv5tVc0etKQ@geopod-ismtpd-2.txt\n",
      "Processing file: _dewCW7FTnCWSKjrDppiJw@geopod-ismtpd-5.txt\n",
      "Processing file: _Dk5VhYJRry4akq_9RLDTA@geopod-ismtpd-4.txt\n",
      "Processing file: _ebVWls2RUS0Bfa7g9dNUw@geopod-ismtpd-9.txt\n",
      "Processing file: _eegOk-ASDOKJjfARCrsBQ@geopod-ismtpd-1.txt\n",
      "Processing file: _gDfSzpjRbmKlpvVGcfEkw@geopod-ismtpd-20.txt\n",
      "Processing file: _g_cV4dhTqa_lxpOvhPk2Q@geopod-ismtpd-1.txt\n",
      "Processing file: _HngbeMoTJO5H43mPVjROw@geopod-ismtpd-17.txt\n",
      "Processing file: _kzBl3-gSna6O0CBD4315Q@geopod-ismtpd-14.txt\n",
      "Data saved to C:\\Users\\ericb\\Desktop\\Research\\542_Project\\data\\test\\warranted_data_test_output\\mailparser_test_output.csv\n"
     ]
    }
   ],
   "source": [
    "import mailparser\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory to search\n",
    "directory = 'C:\\\\Users\\\\ericb\\\\Desktop\\\\Research\\\\Primary@gmail.com\\\\Cleaned_Mail\\\\2023_test\\\\08\\\\'\n",
    "output_csv = 'C:\\\\Users\\\\ericb\\\\Desktop\\\\Research\\\\542_Project\\\\data\\\\test\\\\warranted_data_test_output\\\\mailparser_test_output.csv'\n",
    "\n",
    "# DataFrame to store the results\n",
    "df = pd.DataFrame(columns=['filename', 'body', 'subject', 'text_plain', 'text_html', 'text_not_managed', 'defects', 'defects_categories'])\n",
    "\n",
    "print('Searching files in directory: ' + directory)\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):  # Check for .eml files\n",
    "        print('Processing file: ' + filename)\n",
    "\n",
    "        # Parse the email\n",
    "        mail = mailparser.parse_from_file(os.path.join(directory, filename))\n",
    "\n",
    "        # mail = mailparser.parse_from_bytes(file)\n",
    "        # mail = mailparser.parse_from_file(file)\n",
    "        # mail = mailparser.parse_from_file_msg(file)\n",
    "        # mail = mailparser.parse_from_file_obj(file)\n",
    "        # mail = mailparser.parse_from_string(file)\n",
    "\n",
    "        # print(mail.attachments) # list of all attachments\n",
    "        # print(mail.body)\n",
    "\n",
    "        # print(mail.date) # datetime object in UTC\n",
    "        # print(mail.defects) # defect RFC not compliance\n",
    "        # print(mail.defects_categories)  # only defects categories\n",
    "        # print(mail.delivered_to)\n",
    "        # print(mail.from_)\n",
    "        # print(mail.headers) # dict of all headers\n",
    "        # print(mail.mail) # tokenized mail in a object\n",
    "        # print(mail.message) # email.message.Message object\n",
    "        # print(mail.message_as_string) # message as string\n",
    "        # print(mail.message_id)\n",
    "        # print(mail.received)\n",
    "        # print(mail.subject)\n",
    "        # print(mail.text_plain) # only text plain mail parts in a list\n",
    "        # print(mail.text_html) # only text html mail parts in a list\n",
    "        # print(mail.text_not_managed) # all not managed text (check the warning logs to find content subtype)\n",
    "        # print(mail.to)\n",
    "        # print(mail.to_domains)\n",
    "        # print(mail.timezone) # returns the timezone, offset from UTC\n",
    "        # print(mail.mail_partial) # returns only the mains parts of emails\n",
    "\n",
    "        # Collect data and append to DataFrame\n",
    "        df = df.append({\n",
    "            'filename': filename, \n",
    "            'body': mail.body, \n",
    "            'subject': mail.subject, \n",
    "            'text_plain': mail.text_plain, \n",
    "            'text_html': mail.text_html, \n",
    "            'text_not_managed': mail.text_not_managed, \n",
    "            'defects': str(mail.defects),  # Convert list to string\n",
    "            'defects_categories': str(mail.defects_categories)  # Convert list to string\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "      <th>text_plain</th>\n",
       "      <th>text_html</th>\n",
       "      <th>text_not_managed</th>\n",
       "      <th>defects</th>\n",
       "      <th>defects_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_376f0vXRrWR5R6W9rf4NA@geopod-ismtpd-canary-0.txt</td>\n",
       "      <td>TealNarwhal8831, this FP deal matches your ale...</td>\n",
       "      <td>Home Improvement: 10\" OXO Good Grips Pro Nonst...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[TealNarwhal8831, this FP deal matches your al...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_5hS-rh6QhW8lvdt7USwww@geopod-ismtpd-35.txt</td>\n",
       "      <td>Anime awesomeness awaits!\\n=E2=80=8C =E2=80=8C...</td>\n",
       "      <td>Welcome to Crunchyroll!</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Anime awesomeness awaits!\\n=E2=80=8C =E2=80=8...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_AmJSCjkTaeQv5tVc0etKQ@geopod-ismtpd-2.txt</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nAustralian Politics | The Guardian...</td>\n",
       "      <td>Australian politics: Australia news live: US m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\n\\n\\n\\n\\n\\nAustralian Politics | The Guardia...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_dewCW7FTnCWSKjrDppiJw@geopod-ismtpd-5.txt</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US | ...</td>\n",
       "      <td>The latest op-eds from the Guardian</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US |...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Dk5VhYJRry4akq_9RLDTA@geopod-ismtpd-4.txt</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US | ...</td>\n",
       "      <td>The latest op-eds from the Guardian</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US |...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  _376f0vXRrWR5R6W9rf4NA@geopod-ismtpd-canary-0.txt   \n",
       "1        _5hS-rh6QhW8lvdt7USwww@geopod-ismtpd-35.txt   \n",
       "2         _AmJSCjkTaeQv5tVc0etKQ@geopod-ismtpd-2.txt   \n",
       "3         _dewCW7FTnCWSKjrDppiJw@geopod-ismtpd-5.txt   \n",
       "4         _Dk5VhYJRry4akq_9RLDTA@geopod-ismtpd-4.txt   \n",
       "\n",
       "                                                body  \\\n",
       "0  TealNarwhal8831, this FP deal matches your ale...   \n",
       "1  Anime awesomeness awaits!\\n=E2=80=8C =E2=80=8C...   \n",
       "2  \\n\\n\\n\\n\\n\\nAustralian Politics | The Guardian...   \n",
       "3  \\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US | ...   \n",
       "4  \\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US | ...   \n",
       "\n",
       "                                             subject text_plain text_html  \\\n",
       "0  Home Improvement: 10\" OXO Good Grips Pro Nonst...         []        []   \n",
       "1                            Welcome to Crunchyroll!         []        []   \n",
       "2  Australian politics: Australia news live: US m...         []        []   \n",
       "3                The latest op-eds from the Guardian         []        []   \n",
       "4                The latest op-eds from the Guardian         []        []   \n",
       "\n",
       "                                    text_not_managed  \\\n",
       "0  [TealNarwhal8831, this FP deal matches your al...   \n",
       "1  [Anime awesomeness awaits!\\n=E2=80=8C =E2=80=8...   \n",
       "2  [\\n\\n\\n\\n\\n\\nAustralian Politics | The Guardia...   \n",
       "3  [\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US |...   \n",
       "4  [\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US |...   \n",
       "\n",
       "                                             defects  \\\n",
       "0  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "1  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "2  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "3  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "4  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "\n",
       "                                  defects_categories  \n",
       "0  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "1  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "2  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "3  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "4  {'StartBoundaryNotFoundDefect', 'MultipartInva...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that I have the data, I can clean the textual data for use in the model\n",
    "# print(df['body'][0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file and read it into a DataFrame\n",
    "df_to_clean = pd.read_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import quopri\n",
    "import base64\n",
    "\n",
    "def replace_emojis(text):\n",
    "    return emoji.demojize(text, delimiters=(\"\", \"\"))\n",
    "\n",
    "def replace_urls_based_on_context(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        href = a_tag.get('href', '')\n",
    "        url_type = 'UNSAFE_' if href.startswith('http://') else ''\n",
    "        if a_tag.img:\n",
    "            a_tag.string = f'{url_type}IMAGE_URL'\n",
    "        elif isinstance(a_tag.next, NavigableString) and a_tag.next.strip():\n",
    "            a_tag.string = f'{url_type}LINK_URL'\n",
    "        else:\n",
    "            a_tag.string = f'{url_type}BUTTON_URL'\n",
    "    return str(soup)\n",
    "\n",
    "def replace_urls_in_text(text):\n",
    "    http_url_pattern = re.compile(r'http://\\S+')\n",
    "    text = http_url_pattern.sub('UNSAFE_LINK_URL', text)\n",
    "    https_url_pattern = re.compile(r'https://\\S+')\n",
    "    text = https_url_pattern.sub('LINK_URL', text)\n",
    "    return text\n",
    "\n",
    "def decode_quoted_printable(input_data):\n",
    "    if isinstance(input_data, bytes):\n",
    "        return quopri.decodestring(input_data).decode('utf-8', errors='replace')\n",
    "    else:\n",
    "        return quopri.decodestring(input_data.encode()).decode('utf-8', errors='replace')\n",
    "\n",
    "def decode_base64(text):\n",
    "    return base64.b64decode(text).decode('utf-8', errors='replace')\n",
    "\n",
    "def clean_text(raw_text):\n",
    "\n",
    "    #Remove line breaks and continuation equals signs\n",
    "    raw_text = re.sub(r'=\\n', '', raw_text)\n",
    "    # Decode any quoted-printable text\n",
    "    raw_text = quopri.decodestring(raw_text.encode()).decode('utf-8', errors='replace')\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(raw_text, 'lxml')\n",
    "    \n",
    "    # Remove style and script tags and their content\n",
    "    for tag in soup(['style', 'script', 'img']):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Replace URLs in 'a' tags\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        href = a_tag.get('href', '')\n",
    "        url_type = 'UNSAFE ' if href.startswith('http://') else ''\n",
    "        if a_tag.img:\n",
    "            a_tag.string = f'{url_type}IMAGE URL'\n",
    "        elif isinstance(a_tag.next, NavigableString) and a_tag.next.strip():\n",
    "            a_tag.string = f'{url_type}LINK URL'\n",
    "        else:\n",
    "            a_tag.string = f'{url_type}BUTTON URL'\n",
    "\n",
    "    # Now proceed with extracting text and further cleaning\n",
    "    text = soup.get_text(separator=' ', strip=True)\n",
    "    text = replace_emojis(text)\n",
    "\n",
    "    text = replace_urls_in_text(text)\n",
    "\n",
    "    # Remove any remaining HTML encoded characters\n",
    "    text = re.sub(r'&[a-zA-Z0-9#]+;', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove Zero Width Non-Joiner characters\n",
    "    text = text.replace('\\u200b', '')  # Unicode for ZWNBSP\n",
    "    text = text.replace('\\u200c', '')  # Unicode for ZWNJ\n",
    "    text = text.replace('\\u200d', '')  # Unicode for ZWJ\n",
    "    text = text.replace('\\u200e', '')  # Unicode for LEFT-TO-RIGHT MARK\n",
    "    text = text.replace('\\u200f', '')  # Unicode for RIGHT-TO-LEFT MARK\n",
    "\n",
    "\n",
    "    # Strip string of leading/trailing whitespace\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ericb\\anaconda3\\envs\\machinelearning_20220719\\lib\\site-packages\\bs4\\__init__.py:439: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    }
   ],
   "source": [
    "# print(df_to_clean['body'][1])\n",
    "\n",
    "# run the clean_text function on the subject and body columns\n",
    "df_to_clean['subject'] = df_to_clean['subject'].apply(clean_text)\n",
    "df_to_clean['body'] = df_to_clean['body'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "      <th>text_plain</th>\n",
       "      <th>text_html</th>\n",
       "      <th>text_not_managed</th>\n",
       "      <th>defects</th>\n",
       "      <th>defects_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_376f0vXRrWR5R6W9rf4NA@geopod-ismtpd-canary-0.txt</td>\n",
       "      <td>TealNarwhal8831, this FP deal matches your ale...</td>\n",
       "      <td>Home Improvement: 10\" OXO Good Grips Pro Nonst...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['TealNarwhal8831, this FP deal matches your a...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_5hS-rh6QhW8lvdt7USwww@geopod-ismtpd-35.txt</td>\n",
       "      <td>Anime awesomeness awaits!                     ...</td>\n",
       "      <td>Welcome to Crunchyroll!</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Anime awesomeness awaits!\\n=E2=80=8C =E2=80=...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_AmJSCjkTaeQv5tVc0etKQ@geopod-ismtpd-2.txt</td>\n",
       "      <td>Australian Politics | The Guardian LINK_URL La...</td>\n",
       "      <td>Australian politics: Australia news live: US m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\n\\n\\n\\n\\n\\nAustralian Politics | The Guardi...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_dewCW7FTnCWSKjrDppiJw@geopod-ismtpd-5.txt</td>\n",
       "      <td>The Best of Guardian Opinion US | The Guardian...</td>\n",
       "      <td>The latest op-eds from the Guardian</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US ...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Dk5VhYJRry4akq_9RLDTA@geopod-ismtpd-4.txt</td>\n",
       "      <td>The Best of Guardian Opinion US | The Guardian...</td>\n",
       "      <td>The latest op-eds from the Guardian</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US ...</td>\n",
       "      <td>[{'multipart/alternative': ['StartBoundaryNotF...</td>\n",
       "      <td>{'StartBoundaryNotFoundDefect', 'MultipartInva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  _376f0vXRrWR5R6W9rf4NA@geopod-ismtpd-canary-0.txt   \n",
       "1        _5hS-rh6QhW8lvdt7USwww@geopod-ismtpd-35.txt   \n",
       "2         _AmJSCjkTaeQv5tVc0etKQ@geopod-ismtpd-2.txt   \n",
       "3         _dewCW7FTnCWSKjrDppiJw@geopod-ismtpd-5.txt   \n",
       "4         _Dk5VhYJRry4akq_9RLDTA@geopod-ismtpd-4.txt   \n",
       "\n",
       "                                                body  \\\n",
       "0  TealNarwhal8831, this FP deal matches your ale...   \n",
       "1  Anime awesomeness awaits!                     ...   \n",
       "2  Australian Politics | The Guardian LINK_URL La...   \n",
       "3  The Best of Guardian Opinion US | The Guardian...   \n",
       "4  The Best of Guardian Opinion US | The Guardian...   \n",
       "\n",
       "                                             subject text_plain text_html  \\\n",
       "0  Home Improvement: 10\" OXO Good Grips Pro Nonst...         []        []   \n",
       "1                            Welcome to Crunchyroll!         []        []   \n",
       "2  Australian politics: Australia news live: US m...         []        []   \n",
       "3                The latest op-eds from the Guardian         []        []   \n",
       "4                The latest op-eds from the Guardian         []        []   \n",
       "\n",
       "                                    text_not_managed  \\\n",
       "0  ['TealNarwhal8831, this FP deal matches your a...   \n",
       "1  ['Anime awesomeness awaits!\\n=E2=80=8C =E2=80=...   \n",
       "2  ['\\n\\n\\n\\n\\n\\nAustralian Politics | The Guardi...   \n",
       "3  ['\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US ...   \n",
       "4  ['\\n\\n\\n\\n\\n\\nThe Best of Guardian Opinion US ...   \n",
       "\n",
       "                                             defects  \\\n",
       "0  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "1  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "2  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "3  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "4  [{'multipart/alternative': ['StartBoundaryNotF...   \n",
       "\n",
       "                                  defects_categories  \n",
       "0  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "1  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "2  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "3  {'StartBoundaryNotFoundDefect', 'MultipartInva...  \n",
       "4  {'StartBoundaryNotFoundDefect', 'MultipartInva...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime awesomeness awaits!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Welcome to the internet's premier anime experience! Get started by browsing our always growing library and filling your queue. Then just sit back and enjoy all the anime you can handle! Browse Now ( LINK_URL ) fb ( LINK_URL ) tw ( LINK_URL ) yt ( LINK_URL ) insta ( LINK_URL ) crunchyroll ( LINK_URL ) Crunchyroll PO BOX 405 San Francisco, CA 94104-0405 This email was sent to REDACTED+crunchyroll@gmail.com PRIVACY POLICY ( LINK_URL ) | UNSUBSCRIBE ( LINK_URL ) | TERMS OF SERVICE ( LINK_URL ) * Crunchyroll Anime awesomeness awaits!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           BUTTON_URL BUTTON_URL Welcome to the internet's premier anime experience! Get started by browsing our always growing library and filling your queue. Then just sit back and enjoy all the anime you can handle! BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL BUTTON_URL LINK_URL This email was sent to LINK_URL LINK_URL | LINK_URL | LINK_URL\n"
     ]
    }
   ],
   "source": [
    "print(df_to_clean['body'][1])\n",
    "\n",
    "# save df_to_clean['body'][i] to txt file\n",
    "for i in range (0, len(df_to_clean['body'])):\n",
    "    with open('C:\\\\Users\\\\ericb\\\\Desktop\\\\Research\\\\542_Project\\\\data\\\\test\\\\warranted_data_test_output\\\\mailparser_test_output_body' + str(i) + '.txt', 'w') as f:\n",
    "        f.write(df_to_clean['body'][i])\n",
    "\n",
    "# save df_to_clean['text_not_managed'][i] to txt file\n",
    "for i in range(0, len(df_to_clean['text_not_managed'])):\n",
    "    with open('C:\\\\Users\\\\ericb\\\\Desktop\\\\Research\\\\542_Project\\\\data\\\\test\\\\warranted_data_test_output\\\\mailparser_test_output_text_not_managed' + str(i) + '.txt', 'w') as f:\n",
    "        f.write(df_to_clean['text_not_managed'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning_20220719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
